name: Build Firmware

on:
  push:
    branches: [main, dev]
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main, dev]

env:
  IDF_VERSION: v5.5.2
  IDF_TARGET: esp32p4
  CCACHE_DIR: /opt/actions-runner-esp32/.ccache
  CCACHE_MAXSIZE: 1G
  CCACHE_COMPRESSLEVEL: 6

permissions:
  contents: write
  pull-requests: write

jobs:
  check-changes:
    name: Check Changed Paths
    runs-on: ubuntu-latest
    outputs:
      has_code_changes: ${{ steps.filter.outputs.has_code_changes }}
    steps:
      - name: Checkout code
        if: github.event_name == 'push'
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check if code files changed
        id: filter
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # For PRs, use GitHub API to get only the PR's changed files (not full branch diff)
            CODE_CHANGES=$(gh pr view ${{ github.event.pull_request.number }} \
              --repo ${{ github.repository }} \
              --json files --jq '[.files[].path | select(
                (endswith(".md") | not) and
                (startswith("docs/") | not) and
                (startswith("images/") | not) and
                (startswith(".github/workflows/") | not) and
                (. != "LICENSE") and
                (. != ".gitignore")
              )] | first // empty')
          else
            # For pushes, use git diff between previous and current commit
            BASE=${{ github.event.before }}
            HEAD=${{ github.sha }}
            CODE_CHANGES=$(git diff --name-only "$BASE" "$HEAD" -- \
              ':!**/*.md' ':!docs/**' ':!images/**' ':!LICENSE' ':!.gitignore' ':!.github/workflows/**' \
              | head -1)
          fi

          if [ -n "$CODE_CHANGES" ]; then
            echo "has_code_changes=true" >> $GITHUB_OUTPUT
            echo "Code changes detected, build will run"
          else
            echo "has_code_changes=false" >> $GITHUB_OUTPUT
            echo "Only docs/workflow/non-code changes, skipping build"
          fi

  build:
    needs: check-changes
    if: needs.check-changes.outputs.has_code_changes == 'true'
    runs-on: self-hosted
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          clean: false

      - name: Check for skip CI
        id: check_skip
        run: |
          COMMIT_MSG=$(git log -1 --pretty=%B)
          if echo "$COMMIT_MSG" | grep -qi '\[skip ci\]'; then
            echo "Skipping CI due to [skip ci] in commit message"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Read version
        if: steps.check_skip.outputs.skip != 'true'
        id: version
        run: |
          VERSION=$(cat version.txt | tr -d '[:space:]')
          SHORT_SHA=$(git rev-parse --short HEAD)
          BRANCH=${GITHUB_REF_NAME//\//-}
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "short_sha=$SHORT_SHA" >> $GITHUB_OUTPUT
          echo "branch=$BRANCH" >> $GITHUB_OUTPUT

      - name: Set ESP-IDF paths
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          echo "IDF_PATH=$HOME/esp/esp-idf" >> $GITHUB_ENV
          echo "IDF_TOOLS_PATH=$HOME/esp/tools" >> $GITHUB_ENV

      - name: Ensure ESP-IDF ${{ env.IDF_VERSION }} is installed
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          # Check if ESP-IDF is already installed and at the correct version
          if [ -f "$IDF_PATH/export.sh" ]; then
            INSTALLED_VERSION=$(git -C "$IDF_PATH" describe --tags --exact-match 2>/dev/null || echo "")
            if [ -z "$INSTALLED_VERSION" ] && [ -f "$IDF_PATH/version.txt" ]; then
              INSTALLED_VERSION="v$(cat "$IDF_PATH/version.txt" | tr -d '[:space:]')"
            fi
            echo "ESP-IDF found: ${INSTALLED_VERSION:-unknown}"
            if [ "$INSTALLED_VERSION" = "$IDF_VERSION" ]; then
              echo "Correct version already installed. Skipping."
              exit 0
            else
              echo "Version mismatch ($INSTALLED_VERSION != $IDF_VERSION). Reinstalling..."
              rm -rf "$IDF_PATH"
              rm -rf "$IDF_TOOLS_PATH"
            fi
          fi

          echo "Installing ESP-IDF $IDF_VERSION..."

          echo "::group::Clone ESP-IDF $IDF_VERSION"
          mkdir -p "$(dirname "$IDF_PATH")" "$(dirname "$IDF_TOOLS_PATH")"
          git clone --branch "$IDF_VERSION" --depth 1 --recursive \
            https://github.com/espressif/esp-idf.git "$IDF_PATH"
          echo "::endgroup::"

          echo "::group::Install ESP-IDF tools for $IDF_TARGET"
          "$IDF_PATH/install.sh" "$IDF_TARGET"
          echo "::endgroup::"

          echo "ESP-IDF $IDF_VERSION installation complete."

      - name: Setup ESP-IDF environment
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          . $IDF_PATH/export.sh
          echo "IDF version: $(idf.py --version)"

      - name: Setup ccache
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          # Install ccache if not present
          if ! command -v ccache &>/dev/null; then
            echo "Installing ccache..."
            sudo apt-get update -qq && sudo apt-get install -y -qq ccache
          fi
          echo "ccache version: $(ccache --version | head -1)"
          ccache --zero-stats
          ccache --show-config | grep -E "max_size|cache_dir|compression"

      - name: Build project
        if: steps.check_skip.outputs.skip != 'true'
        env:
          IDF_CCACHE_ENABLE: 1
        run: |
          . $IDF_PATH/export.sh
          idf.py build

      - name: Show ccache stats
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          ccache --show-stats

      - name: Generate firmware binaries
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          . $IDF_PATH/export.sh
          mkdir -p firmware

          # Detect app binary from project_description.json
          APP_BIN=$(python3 -c "
          import json
          with open('build/project_description.json') as f:
              d = json.load(f)
          print('build/' + d['app_bin'])
          ")

          # Merge factory binary (bootloader + partition table + app)
          python3 -m esptool --chip esp32p4 merge_bin \
            --flash_mode dio \
            --flash_size 32MB \
            --flash_freq 80m \
            -o firmware/nina-display-factory.bin \
            0x2000  build/bootloader/bootloader.bin \
            0x8000  build/partition_table/partition-table.bin \
            0x20000 "$APP_BIN"

          # Copy app binary as OTA file
          cp "$APP_BIN" firmware/nina-display-ota.bin

          # Report sizes
          echo "Factory: $(du -h firmware/nina-display-factory.bin | cut -f1)"
          echo "OTA:     $(du -h firmware/nina-display-ota.bin | cut -f1)"

      - name: Extract firmware metrics
        if: steps.check_skip.outputs.skip != 'true'
        id: metrics
        run: |
          . $IDF_PATH/export.sh
          
          # Get binary sizes
          FACTORY_SIZE=$(stat -c%s firmware/nina-display-factory.bin 2>/dev/null || stat -f%z firmware/nina-display-factory.bin)
          OTA_SIZE=$(stat -c%s firmware/nina-display-ota.bin 2>/dev/null || stat -f%z firmware/nina-display-ota.bin)
          
          # Convert to human readable using Python (bc not available on all runners)
          FACTORY_MB=$(python3 -c "print(f'{$FACTORY_SIZE / 1024 / 1024:.2f}')")
          OTA_MB=$(python3 -c "print(f'{$OTA_SIZE / 1024 / 1024:.2f}')")
          
          # Extract PSRAM config from sdkconfig (exact key match to avoid multi-line grep)
          PSRAM_SPEED=$(grep '^CONFIG_SPIRAM_SPEED=' sdkconfig 2>/dev/null | cut -d'=' -f2 || echo "200")

          # Get flash size from sdkconfig (exact key match)
          FLASH_SIZE=$(grep '^CONFIG_ESPTOOLPY_FLASHSIZE=' sdkconfig | cut -d'"' -f2 || echo "32MB")
          
          # Get memory usage from size output
          if [ -f build/nina-display.map ]; then
            DRAM_USED=$(grep -A 10 "Memory region.*Used Size" build/nina-display.map | grep "dram0" | awk '{print $2}' || echo "0")
            IRAM_USED=$(grep -A 10 "Memory region.*Used Size" build/nina-display.map | grep "iram0" | awk '{print $2}' || echo "0")
          else
            DRAM_USED="N/A"
            IRAM_USED="N/A"
          fi
          
          # Create metrics JSON
          cat > /tmp/firmware-metrics.json << EOF
          {
            "flash_size": "$FLASH_SIZE",
            "psram": "32MB @ ${PSRAM_SPEED}MHz",
            "factory_size": "${FACTORY_MB} MB",
            "ota_size": "${OTA_MB} MB",
            "dram_used": "$DRAM_USED",
            "iram_used": "$IRAM_USED",
            "esp_idf": "${{ env.IDF_VERSION }}",
            "target": "${{ env.IDF_TARGET }}",
            "build_date": "$(date -u +%Y-%m-%d)",
            "branch": "${GITHUB_REF_NAME}",
            "commit": "${{ steps.version.outputs.short_sha }}"
          }
          EOF
          
          cat /tmp/firmware-metrics.json
          
          echo "factory_mb=$FACTORY_MB" >> $GITHUB_OUTPUT
          echo "ota_mb=$OTA_MB" >> $GITHUB_OUTPUT

      - name: Update badge metrics
        if: steps.check_skip.outputs.skip != 'true' && github.ref == 'refs/heads/main'
        run: |
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Store current state
          CURRENT_BRANCH=${GITHUB_REF_NAME}
          CURRENT_COMMIT=$(git rev-parse HEAD)

          # Stash any working tree changes (e.g. firmware binaries from build)
          git stash --include-untracked

          # Fetch badges branch if it exists, or create orphan
          git fetch origin badges:badges 2>/dev/null || git checkout --orphan badges

          # Switch to badges branch
          if git show-ref --verify --quiet refs/heads/badges; then
            git checkout badges
          fi
          
          # Clean all except .git
          git rm -rf . 2>/dev/null || true
          
          # Copy metrics file
          cp /tmp/firmware-metrics.json .
          
          # Commit and push
          git add firmware-metrics.json
          if git commit -m "Update firmware metrics for ${{ steps.version.outputs.short_sha }}"; then
            git push origin badges --force
          fi
          
          # Return to original state
          git checkout $CURRENT_COMMIT
          git checkout $CURRENT_BRANCH
          git stash pop 2>/dev/null || true

      - name: Upload firmware artifacts
        if: steps.check_skip.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: firmware-${{ steps.version.outputs.branch }}-${{ steps.version.outputs.short_sha }}
          path: firmware/
          retention-days: 30

      - name: Determine tag
        if: steps.check_skip.outputs.skip != 'true'
        id: tag
        run: |
          BRANCH=${GITHUB_REF_NAME}

          if [ "$BRANCH" = "main" ]; then
            VERSION=$(cat version.txt | tr -d '[:space:]')
            TAG="v${VERSION}"
          else
            # Use latest main release version so pre-releases sort correctly
            LATEST_MAIN_TAG=$(git tag -l 'v[0-9]*.[0-9]*.[0-9]*' --sort=-v:refname | grep -v '-' | head -1)
            if [ -n "$LATEST_MAIN_TAG" ]; then
              BASE_VERSION=${LATEST_MAIN_TAG#v}
            else
              BASE_VERSION=$(cat version.txt | tr -d '[:space:]')
            fi
            # Count existing tags with this prefix to auto-increment
            PREFIX="v${BASE_VERSION}-${BRANCH}."
            EXISTING=$(git tag -l "${PREFIX}*" | wc -l)
            NEXT=$((EXISTING + 1))
            TAG="v${BASE_VERSION}-${BRANCH}.${NEXT}"
          fi

          echo "tag=$TAG" >> $GITHUB_OUTPUT
          if [ "$BRANCH" = "main" ]; then
            echo "is_prerelease=false" >> $GITHUB_OUTPUT
          else
            echo "is_prerelease=true" >> $GITHUB_OUTPUT
          fi

      - name: Generate changelog
        if: steps.check_skip.outputs.skip != 'true'
        id: changelog
        run: |
          PREV_TAG=$(git describe --tags --abbrev=0 HEAD^ 2>/dev/null || echo "")
          if [ -n "$PREV_TAG" ]; then
            CHANGES=$(git log ${PREV_TAG}..HEAD --pretty=format:"- %s (%h)" --no-merges)
          else
            CHANGES=$(git log --pretty=format:"- %s (%h)" --no-merges -20)
          fi
          # Filter out noise commits (version bumps, skip ci)
          echo "$CHANGES" | grep -v '\[skip ci\]' | grep -v 'chore: bump version' > /tmp/changelog.txt || true
          # Keep unfiltered as fallback
          echo "$CHANGES" > /tmp/changelog_raw.txt
          echo "prev_tag=$PREV_TAG" >> $GITHUB_OUTPUT

      - name: Summarize release changes with Gemini
        if: steps.check_skip.outputs.skip != 'true'
        id: release_summary
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          set +e

          CHANGES=$(cat /tmp/changelog.txt)

          # Skip if no meaningful changes or no API key
          if [ -z "$CHANGES" ] || [ -z "$GOOGLE_API_KEY" ]; then
            echo "ai_available=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Use python3 for JSON handling (jq not available on self-hosted runner)
          python3 << 'PYEOF'
          import json, os, re, subprocess, sys

          with open('/tmp/changelog.txt') as f:
              changes = f.read().strip()

          api_key = os.environ.get('GOOGLE_API_KEY', '')
          if not changes or not api_key:
              print("No changes or API key, skipping")
              sys.exit(0)

          prompt = """You are writing release notes for an ESP32 astrophotography display firmware. Given the commit list below, produce TWO things:

          1. A SUMMARY: 1-2 sentences in plain language describing what changed in this release and why it matters to users. Focus on user-visible impact.

          2. A CHANGES list: One line per commit in this exact format:
          - <plain language description of what the commit does> — <hash>

          Rules for the CHANGES list:
          - Each line must end with the original commit hash after a " — " separator
          - Rewrite the commit message into clear, plain language (drop prefixes like "feat:", "fix:", "bugfix:")
          - Focus on WHAT changed and WHY, not implementation details
          - Keep each line under 100 characters (excluding the hash)
          - Do NOT add, remove, or merge commits — output exactly one line per input commit
          - Do NOT use emojis

          Writing style — write like a developer, NOT like AI marketing copy:
          - NEVER use: "introduces", "enhances", "leverages", "utilizes", "facilitates", "ensures", "enables", "allows"
          - NEVER use: "This release..." to start the summary
          - Use direct, active voice: "Fixed X", "Added Y", "Screen now does Z"
          - Good: "Fixed remaining time calculation being off by one exposure"
          - Bad: "Resolved an issue where the target remaining time was calculated incorrectly"

          ## Commits
          """ + changes + """

          ## Output format (follow exactly)
          SUMMARY: <your summary here>

          CHANGES:
          - <description> — <hash>
          - <description> — <hash>"""

          payload = json.dumps({
              "contents": [{"parts": [{"text": prompt}]}],
              "generationConfig": {"temperature": 0.3, "maxOutputTokens": 4096}
          })

          try:
              result = subprocess.run(
                  ["curl", "-s", "-X", "POST",
                   "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent",
                   "-H", "Content-Type: application/json",
                   "-H", f"X-goog-api-key: {api_key}",
                   "-d", payload],
                  capture_output=True, text=True, timeout=30
              )
              response = json.loads(result.stdout)
              full_text = response["candidates"][0]["content"]["parts"][0]["text"]
          except Exception as e:
              print(f"AI summary failed: {e}")
              sys.exit(0)

          # Extract summary line
          summary_match = re.search(r'^SUMMARY:\s*(.+)$', full_text, re.MULTILINE)
          # Extract changes (everything after CHANGES: line)
          changes_match = re.search(r'^CHANGES:\s*\n([\s\S]+)', full_text, re.MULTILINE)

          if summary_match and changes_match:
              with open('/tmp/release_summary.txt', 'w') as f:
                  f.write(summary_match.group(1).strip())
              with open('/tmp/release_changes.txt', 'w') as f:
                  f.write(changes_match.group(1).strip())
              # Signal success via a marker file
              with open('/tmp/ai_available', 'w') as f:
                  f.write('true')
              print("AI summary generated successfully")
          else:
              print("Could not parse AI response")
          PYEOF

          if [ -f /tmp/ai_available ]; then
            echo "ai_available=true" >> $GITHUB_OUTPUT
          else
            echo "ai_available=false" >> $GITHUB_OUTPUT
          fi

      - name: Check for network_adapter.bin
        if: steps.check_skip.outputs.skip != 'true'
        id: network_adapter
        run: |
          if [ -f "network_adapter.bin" ]; then
            cp network_adapter.bin firmware/
            echo "included=true" >> $GITHUB_OUTPUT
          else
            echo "included=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate release notes
        if: steps.check_skip.outputs.skip != 'true'
        run: |
          TAG="${{ steps.tag.outputs.tag }}"
          PREV_TAG="${{ steps.changelog.outputs.prev_tag }}"
          VERSION=$(cat version.txt | tr -d '[:space:]')
          BRANCH=${GITHUB_REF_NAME}
          FACTORY_MB="${{ steps.metrics.outputs.factory_mb }}"
          OTA_MB="${{ steps.metrics.outputs.ota_mb }}"

          if [ -n "$PREV_TAG" ]; then
            COMPARE_URL="https://github.com/chvvkumar/ESP32-P4-NINA-Display/compare/${PREV_TAG}...${TAG}"
          else
            COMPARE_URL=""
          fi

          AI_AVAILABLE="${{ steps.release_summary.outputs.ai_available }}"
          export TAG PREV_TAG VERSION BRANCH COMPARE_URL FACTORY_MB OTA_MB AI_AVAILABLE
          python3 << 'PYEOF'
          import os, json
          tag = os.environ['TAG']
          prev_tag = os.environ.get('PREV_TAG', '')
          version = os.environ['VERSION']
          branch = os.environ['BRANCH']
          compare_url = os.environ.get('COMPARE_URL', '')
          factory_mb = os.environ.get('FACTORY_MB', 'N/A')
          ota_mb = os.environ.get('OTA_MB', 'N/A')
          ai_available = os.environ.get('AI_AVAILABLE', 'false') == 'true'

          # Load metrics if available
          try:
              with open('/tmp/firmware-metrics.json') as f:
                  metrics = json.load(f)
          except:
              metrics = {}

          # Load AI summary and changes if available, otherwise fall back to raw changelog
          summary = ''
          if ai_available:
              try:
                  with open('/tmp/release_summary.txt') as f:
                      summary = f.read().strip()
                  with open('/tmp/release_changes.txt') as f:
                      changes = f.read().strip()
              except:
                  ai_available = False

          if not ai_available:
              with open('/tmp/changelog.txt') as f:
                  changes = f.read().strip()

          since = f'### Changes since {prev_tag}' if prev_tag else '### Recent Changes'
          lines = [
              f'## NINA Display {tag}',
              '',
              f'**Branch:** {branch}',
              f'**Version:** {version}',
              '**Built with:** ESP-IDF v5.5.2',
              '',
              '### Build Specifications',
              f'- **Target:** {metrics.get("target", "esp32p4")}',
              f'- **Flash Size:** {metrics.get("flash_size", "32MB")}',
              f'- **PSRAM:** {metrics.get("psram", "32MB @ 200MHz")}',
              f'- **Factory Binary:** {factory_mb} MB',
              f'- **OTA Binary:** {ota_mb} MB',
              '',
          ]
          if summary:
              lines += ['### Summary', summary, '']
          lines += [since, changes, '']
          if compare_url:
              lines.append(f'**Full Changelog**: {compare_url}')
              lines.append('')
          lines += [
              '### Firmware Files',
              '| File | Description |',
              '|------|-------------|',
              '| `nina-display-factory.bin` | Full factory image (flash at 0x0000) |',
              '| `nina-display-ota.bin` | OTA update binary (upload via web UI) |',
              '',
              '### Flashing',
              '- **Factory:** Use [ESP Web Flasher](https://espressif.github.io/esptool-js/) — flash at address `0x0000`',
              '- **OTA:** Upload `nina-display-ota.bin` via the device web UI at `http://<device-ip>/`',
              '',
          ]
          with open('/tmp/release-notes.md', 'w') as f:
              f.write('\n'.join(lines))
          PYEOF

      - name: Create release
        if: steps.check_skip.outputs.skip != 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          TAG="${{ steps.tag.outputs.tag }}"
          IS_PRERELEASE=${{ steps.tag.outputs.is_prerelease }}

          PRERELEASE_FLAG=""
          if [ "$IS_PRERELEASE" = "true" ]; then
            PRERELEASE_FLAG="--prerelease"
          fi

          # Create or move git tag to current commit
          git tag -f "$TAG"
          git push origin "$TAG" --force

          # Delete existing release if present, then create fresh
          gh release delete "$TAG" --yes 2>/dev/null || true
          gh release create "$TAG" \
            firmware/nina-display-factory.bin \
            firmware/nina-display-ota.bin \
            --title "$TAG" \
            --notes-file /tmp/release-notes.md \
            $PRERELEASE_FLAG

      - name: Cleanup old pre-releases
        if: steps.check_skip.outputs.skip != 'true' && steps.tag.outputs.is_prerelease == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          CURRENT_TAG="${{ steps.tag.outputs.tag }}"
          echo "Cleaning up old pre-releases (keeping latest 2)..."

          # List all pre-releases sorted newest first, skip the 2 most recent, delete the rest
          gh release list --limit 50 --json tagName,isPrerelease \
            -q '[.[] | select(.isPrerelease)] | .[2:] | .[].tagName' | \
          while read -r old_tag; do
            echo "Deleting old pre-release: $old_tag"
            gh release delete "$old_tag" --yes --cleanup-tag 2>/dev/null || true
          done

      - name: Bump version for next release
        if: steps.check_skip.outputs.skip != 'true' && github.ref == 'refs/heads/main'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          CURRENT_VERSION=$(cat version.txt | tr -d '[:space:]')
          IFS='.' read -r MAJOR MINOR PATCH <<< "$CURRENT_VERSION"
          PATCH=$((PATCH + 1))
          NEW_VERSION="$MAJOR.$MINOR.$PATCH"

          echo "$NEW_VERSION" > version.txt
          echo "Bumped version: $CURRENT_VERSION -> $NEW_VERSION"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add version.txt
          git commit -m "chore: bump version to $NEW_VERSION [skip ci]"
          git push origin main

  pr-commit-summary:
    name: Generate PR Summary
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Collect commit information
        id: collect
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Fetching commits for PR #${{ github.event.pull_request.number }}"

          # Get detailed commit information
          gh pr view ${{ github.event.pull_request.number }} --json commits \
            --jq '.commits[] | "**Commit \(.oid[0:7])** by \(.authors[0].name // "Unknown")\nMessage: \(.messageHeadline)\n\(.messageBody // "")\n---"' \
            > commits.txt

          # Get changed files with stats
          gh pr view ${{ github.event.pull_request.number }} --json files \
            --jq '.files[] | "- `\(.path)` (+\(.additions)/-\(.deletions))"' \
            > files.txt

          # Get changed files excluding GitHub workflows (for AI summary)
          gh pr view ${{ github.event.pull_request.number }} --json files \
            --jq '.files[] | select(.path | startswith(".github/workflows/") | not) | "- `\(.path)` (+\(.additions)/-\(.deletions))"' \
            > files_for_ai.txt

          # Check if changes are only in GitHub Actions workflows
          NON_WORKFLOW_CHANGES=$(gh pr view ${{ github.event.pull_request.number }} --json files \
            --jq '[.files[] | select(.path | startswith(".github/workflows/") | not)] | length')

          if [ "$NON_WORKFLOW_CHANGES" -eq 0 ]; then
            echo "skip_summary=true" >> $GITHUB_OUTPUT
            echo "Skipping AI summary - changes are only in GitHub Actions workflows"
          else
            echo "skip_summary=false" >> $GITHUB_OUTPUT
            echo "Will generate AI summary for code changes (excluding workflow files)"
          fi

          # Get commit count
          COMMIT_COUNT=$(gh pr view ${{ github.event.pull_request.number }} --json commits --jq '.commits | length')
          echo "commit_count=$COMMIT_COUNT" >> $GITHUB_OUTPUT

          echo "Collected $COMMIT_COUNT commits"

      - name: Generate summary with Google Gemini
        id: summarize
        if: steps.collect.outputs.skip_summary == 'false'
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          PR_TITLE_RAW: ${{ github.event.pull_request.title }}
          PR_BODY_RAW: ${{ github.event.pull_request.body }}
        run: |
          set +e  # Don't exit immediately on error

          # Read collected data
          COMMITS=$(cat commits.txt)
          FILES=$(cat files_for_ai.txt)

          # Escape special characters for JSON (use env vars to avoid shell injection)
          COMMITS_ESCAPED=$(echo "$COMMITS" | jq -Rs .)
          FILES_ESCAPED=$(echo "$FILES" | jq -Rs .)
          PR_TITLE=$(printenv PR_TITLE_RAW | jq -Rs .)
          PR_BODY=$(printenv PR_BODY_RAW | jq -Rs .)

          # Build the prompt
          read -r -d '' PROMPT << 'EOF'
          You are a code review assistant. Analyze the following pull request and provide a concise PR title and a categorized summary of changes.

          **IMPORTANT:** Focus ONLY on the actual code changes listed below. Do NOT mention or summarize any GitHub Actions workflow files (.github/workflows/) as those have been filtered out. Do NOT use any emojis anywhere in your output.

          ## Pull Request Details
          **Title:** %PR_TITLE%
          **Description:** %PR_BODY%

          ## Commits in this PR
          %COMMITS%

          ## Files Changed (excluding workflow files)
          %FILES%

          ## Your Task
          Provide your output in EXACTLY this format:

          TITLE: <a concise PR title following the rules below>

          ### Summary
          <1-3 sentences in plain language explaining what this PR does and why. Focus on the user-visible impact or the problem being solved, not implementation details. A non-developer should be able to understand the gist.>

          ### Changes
          <Bullet list of specific changes. Group related items together. Each bullet should be one clear sentence. Use plain language — avoid jargon like "TOCTOU race" or "TLS-based HTTP context" unless there's no simpler way to say it. Focus on WHAT changed and WHY, not HOW.>

          Do NOT use emojis. Do NOT include any other sections, headers, or conclusions.
          Do NOT use sub-categories like "Features:", "Bug Fixes:" etc. — just a flat bullet list.
          Limit to at most 8 bullets. Combine trivial related changes into a single bullet.

          ## Writing Style Rules (follow strictly)
          Write like a developer writing notes for other developers — direct and concise.
          NEVER use these AI filler patterns:
          - "This pull request..." or "This PR..." — just state what changed
          - "Introduces", "enhances", "leverages", "utilizes", "facilitates"
          - "Implemented logic to..." — just say what it does
          - "...for improved/better/enhanced..." — say the specific outcome
          - "...ensuring that..." or "...allowing the device to..."
          - "Updated internal structures to support..." — say what the change actually is
          - Passive voice like "was added", "has been implemented"
          Write as if you're explaining to a teammate in a chat message, not writing marketing copy.
          Good: "Screen now sleeps after 5 min of inactivity to save power"
          Bad: "Implemented automatic screen sleep functionality to enable power-saving capabilities"

          ## TITLE Rules (follow these strictly)
          - Identify the SINGLE most important or impactful change in this PR and use that as the title
          - Do NOT list multiple changes separated by commas or "and" — pick the one that matters most
          - Keep it under 60 characters
          - Use lowercase after the prefix
          - Start with a conventional commit prefix: feat:, fix:, refactor:, docs:, perf:, chore:
          - Be specific about WHAT changed, not vague (e.g. "feat: add screen sleep timeout" not "Add new feature and improvements")
          - If the PR is truly about one bug fix and one feature, prefer the feature for the title
          - Good examples: "feat: add MQTT Home Assistant integration", "fix: memory leak in WebSocket reconnect", "refactor: split polling logic into tiered stages"
          - Bad examples: "Update UI, Fix Bugs, and Improve Config", "Various improvements and fixes", "Enhance app with new features"
          EOF

          # Replace placeholders (remove jq quotes)
          PROMPT="${PROMPT//%PR_TITLE%/$(echo $PR_TITLE | jq -r .)}"
          PROMPT="${PROMPT//%PR_BODY%/$(echo $PR_BODY | jq -r .)}"
          PROMPT="${PROMPT//%COMMITS%/$(echo $COMMITS_ESCAPED | jq -r .)}"
          PROMPT="${PROMPT//%FILES%/$(echo $FILES_ESCAPED | jq -r .)}"

          # Make API request to Google Gemini
          RESPONSE=$(curl -s -X POST "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent" \
            -H "Content-Type: application/json" \
            -H "X-goog-api-key: $GOOGLE_API_KEY" \
            -d "$(jq -n \
              --arg prompt "$PROMPT" \
              '{
                contents: [
                  {
                    parts: [
                      {
                        text: $prompt
                      }
                    ]
                  }
                ],
                generationConfig: {
                  temperature: 0.3,
                  maxOutputTokens: 8192
                }
              }')")

          # Check for errors
          if [ -z "$RESPONSE" ]; then
            echo "Error: Empty response from API"
            exit 1
          fi

          if echo "$RESPONSE" | jq -e '.error' > /dev/null 2>&1; then
            echo "Error from API:"
            echo "$RESPONSE" | jq '.'
            exit 1
          fi

          if ! echo "$RESPONSE" | jq -e '.candidates[0].content.parts[0].text' > /dev/null 2>&1; then
            echo "Invalid response structure"
            exit 1
          fi

          # Extract full response text
          FULL_TEXT=$(echo "$RESPONSE" | jq -r '.candidates[0].content.parts[0].text')

          # Extract title (first line matching "TITLE: ...")
          echo "$FULL_TEXT" | grep '^TITLE:' | sed 's/^TITLE:\s*//' > ai_title.txt

          # Extract body (everything after the TITLE line)
          echo "$FULL_TEXT" | sed '1{/^TITLE:/d}' > summary.md

      - name: Update PR title and body with summary
        if: steps.collect.outputs.skip_summary == 'false'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read the generated summary and AI title
            const summary = fs.readFileSync('summary.md', 'utf8').trim();
            const aiTitle = fs.readFileSync('ai_title.txt', 'utf8').trim();
            const commitCount = '${{ steps.collect.outputs.commit_count }}';
            const timestamp = new Date().toISOString();

            // Get current PR details
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
            });

            // Use AI-generated title if available, otherwise keep original
            const newTitle = aiTitle || pr.title;

            // Create PR body with Changes by Category section
            const newBody = `${summary}

            ---
            <sub>Analyzed **${commitCount}** commit(s) | Updated: ${timestamp} | Generated by GitHub Actions</sub>`;

            // Update the PR
            await github.rest.pulls.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              title: newTitle,
              body: newBody
            });

            console.log(`Updated PR #${context.issue.number}`);
            console.log(`New title: ${newTitle}`);
